---
title: ğŸ¯ Kernel Regression
layout: default
parent: ğŸ¤– Machine Learning
---

# ğŸ¯ Kernel Regression

## Theory
Kernel Regression is similar to [ğŸ  K-Nearest Neighbors](/public-garden/notes/Machine Learning/Supervised Learning/ğŸ  K-Nearest Neighbors.html). However, instead of a hard $$K$$ cutoff, we get the average across all data points weighted by their similarity as measured by [ğŸ¿ Kernels](/public-garden/notes/Mathematics/ğŸ¿ Kernels.html).

## Prediction
Given input $$x$$ and training data $$D$$,
1. For regression, return 

$$

\hat{y} = \frac{\sum_{i=1}^n k(x, x_i)y_i}{\sum_{i=1}^n k(x, x_i)}

$$

2. For classification, return 

$$

\hat{y} = sign(\sum_{i=1}^n k(x, x_i) y_i)

$$

